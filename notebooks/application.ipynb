{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.signal import butter, filtfilt\n",
    "import torch\n",
    "import pywt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_from_csv(file_path):\n",
    "    # Read the csv file\n",
    "    df_in = pd.read_csv(file_path)\n",
    "\n",
    "    # Get the header row\n",
    "    header_row = list(df_in.columns)\n",
    "\n",
    "    # Convert the header row to integer values\n",
    "    header_row = list(map(int, header_row))\n",
    "\n",
    "    # Create a DataFrame from the header row\n",
    "    header_df = pd.DataFrame([header_row], columns=df_in.columns)\n",
    "\n",
    "    # Concatenate the header row with the original DataFrame\n",
    "    df_imm = pd.concat([header_df, df_in], ignore_index=True)\n",
    "\n",
    "    # Reset column names\n",
    "    df_imm.columns = range(df_imm.shape[1])\n",
    "\n",
    "    # Remove the first column\n",
    "    df_imm = df_imm.drop(0, axis=1)\n",
    "\n",
    "    df_out = df_imm.T\n",
    "    \n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score(epoch):    \n",
    "    # Apply z-score normalization to each channel, saved in epoch\n",
    "    for i in range(epoch.shape[0]):\n",
    "        channel_epoch = epoch.iloc[i]\n",
    "        mean = np.mean(channel_epoch)\n",
    "        std = np.std(channel_epoch)\n",
    "        z_scored_epoch = (channel_epoch - mean) / std\n",
    "        epoch.iloc[i] = z_scored_epoch\n",
    "    \n",
    "    return epoch\n",
    "\n",
    "def frequency_to_scale(freq, wavelet='morl', sampling_rate=250):\n",
    "    # For the Morlet wavelet, scales are inversely proportional to frequency\n",
    "    center_freq = pywt.central_frequency(wavelet)\n",
    "    return center_freq / (freq / sampling_rate)\n",
    "\n",
    "def apply_wavelet_transform(data_norm, wavelet='morl', freq_range=(8, 30), sampling_rate=250):\n",
    "    \"\"\"\n",
    "    Apply wavelet transform to EEG data.\n",
    "    \n",
    "    Parameters:\n",
    "    data_norm (ndarray): 2D array with shape (channels, time_points)\n",
    "    wavelet (str): Wavelet type (default 'morl')\n",
    "    freq_range (tuple): Frequency range for the CWT (default (8, 30) Hz)\n",
    "    sampling_rate (int): Sampling rate of the EEG data (default 250 Hz)\n",
    "    \n",
    "    Returns:\n",
    "    ndarray: 3D array with shape (channels, scales, time_points)\n",
    "    \"\"\"\n",
    "    n_channels, n_times = data_norm.shape\n",
    "    # Define scales based on the desired frequency range\n",
    "    scales = frequency_to_scale(np.arange(freq_range[0], freq_range[1]+1), wavelet=wavelet, sampling_rate=sampling_rate)\n",
    "    \n",
    "    coeffs = []\n",
    "    for i in range(n_channels):\n",
    "        # Compute the wavelet transform coefficients\n",
    "        coef, _ = pywt.cwt(data_norm.iloc[i], scales=scales, wavelet=wavelet)\n",
    "        coeffs.append(coef)\n",
    "    \n",
    "    # Stack coefficients to form a 3D tensor\n",
    "    coeffs_done = np.stack(coeffs, axis=0)\n",
    "    \n",
    "    return coeffs_done\n",
    "\n",
    "def apply_bandpass_filter(signal, b, a):\n",
    "    return filtfilt(b, a, signal)\n",
    "\n",
    "def filtering_raw_signal(file_path):\n",
    "    # Load the data, in dataframe format\n",
    "    data_raw = df_from_csv(file_path)\n",
    "    \n",
    "    # Filter parameters\n",
    "    l_freq = 8\n",
    "    h_freq = 30\n",
    "    order = 5\n",
    "    fs = 250\n",
    "\n",
    "    nyquist = 0.5 * fs\n",
    "    low = l_freq / nyquist\n",
    "    high = h_freq / nyquist\n",
    "\n",
    "    # Calculate filter coefficients\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    \n",
    "    # Apply the filter to each row independently\n",
    "    for i in range(data_raw.shape[0]):\n",
    "        data_raw.iloc[i] = apply_bandpass_filter(data_raw.iloc[i], b, a)\n",
    "        \n",
    "    # Convert filtered data back to DataFrame\n",
    "    data_filtered = pd.DataFrame(data_raw)\n",
    "    \n",
    "    # Split data into segments of 0.5 seconds, for epoching\n",
    "    epoch_size = int(fs * 0.5)  # Number of samples in 0.5 seconds\n",
    "    epochs = [data_filtered.iloc[:, i:i+epoch_size] for i in range(0, len(data_filtered.columns), epoch_size)]\n",
    "    \n",
    "    # Create an empty list to store the transformed epochs\n",
    "    transformed_epochs = []\n",
    "    \n",
    "    # Z-score normalization and wavelet transform for each segment and stack them into a tensor (4D array), \n",
    "    # Loop through each epoch\n",
    "    for epoch in epochs:\n",
    "        # Z-score each epoch\n",
    "        epoch_norm = z_score(epoch)\n",
    "        \n",
    "        # # Apply wavelet transformation\n",
    "        wavelet_tensor = apply_wavelet_transform(epoch_norm)\n",
    "        \n",
    "        # Append the transformed epoch to the list\n",
    "        transformed_epochs.append(wavelet_tensor)\n",
    "        \n",
    "        \n",
    "    # Convert the list of epochs into a tensor dataset\n",
    "    tensor_dataset = torch.tensor(transformed_epochs, dtype=torch.float32)  # Ensure the tensor is float32\n",
    "     \n",
    "    return tensor_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Advanced_EEG_MI_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Advanced_EEG_MI_CNN, self).__init__()\n",
    "        # First convolutional layer with Batch Normalization and ReLU activation\n",
    "        self.conv1 = nn.Conv2d(in_channels=8, out_channels=32, kernel_size=(3, 3), padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        \n",
    "        # Second convolutional layer with Batch Normalization and ReLU activation\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        \n",
    "        # Third convolutional layer with Batch Normalization and ReLU activation\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3), padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool3 = nn.AvgPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        \n",
    "        # Dropout layer to prevent overfitting\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(128 * 2 * 15, 256)  # Adjust based on final output size after conv layers\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64, 2)  # Assuming 2 classes for binary classification\n",
    "\n",
    "    def _forward_conv_layers(self, x):\n",
    "        # Forward pass through the first convolutional layer\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        # Forward pass through the second convolutional layer\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "        # Forward pass through the third convolutional layer\n",
    "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through the convolutional layers\n",
    "        x = self._forward_conv_layers(x)\n",
    "        # Flatten the tensor to feed into fully connected layers\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # Forward pass through the first fully connected layer with ReLU and dropout\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        # Forward pass through the second fully connected layer with ReLU\n",
    "        x = F.relu(self.fc2(x))\n",
    "        # Output layer\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Advanced_EEG_MI_CNN_LSTM_Transformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Advanced_EEG_MI_CNN_LSTM_Transformer, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=8, out_channels=32, kernel_size=(3, 3), padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3), padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool3 = nn.AvgPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        \n",
    "        # LSTM layer\n",
    "        self.lstm = nn.LSTM(input_size=128*2*15, hidden_size=128, num_layers=1, batch_first=True)\n",
    "        \n",
    "        # Transformer layer\n",
    "        self.transformer_encoder_layer = nn.TransformerEncoderLayer(d_model=128, nhead=8)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.transformer_encoder_layer, num_layers=1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(128, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64, 2)\n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        \n",
    "    def _forward_conv_layers(self, x):\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        # Forward pass through convolutional layers\n",
    "        x = self._forward_conv_layers(x)\n",
    "        \n",
    "        # Flatten for LSTM\n",
    "        x = x.view(batch_size, -1, 128*2*15)\n",
    "        \n",
    "        # Forward pass through LSTM\n",
    "        x, (hn, cn) = self.lstm(x)\n",
    "        \n",
    "        # Transformer encoding\n",
    "        x = self.transformer_encoder(x)\n",
    "        \n",
    "        # Take the output from the last sequence step for classification\n",
    "        x = x[:, -1, :]\n",
    "        \n",
    "        # Forward pass through fully connected layers\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cnn(model_path, data_to_predict):    \n",
    "    # Load the state dictionary\n",
    "    state_dict = torch.load(model_path)\n",
    "\n",
    "    # Initialize the model and load the state dictionary\n",
    "    model = Advanced_EEG_MI_CNN_LSTM_Transformer()\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "\n",
    "    # Create TensorDataset and DataLoader\n",
    "    tensor_dataset = filtering_raw_signal(data_to_predict)\n",
    "    dataset = TensorDataset(tensor_dataset)\n",
    "    dataloader = DataLoader(dataset, batch_size=10, shuffle=False)\n",
    "\n",
    "    # Classify each sample\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            # Assuming your data is in the first element of the batch\n",
    "            inputs = batch[0]\n",
    "            \n",
    "            # Move inputs to the same device as the model\n",
    "            inputs = inputs.to(next(model.parameters()).device)\n",
    "            \n",
    "            # Get model predictions\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Assuming the model output is logits, apply softmax to get probabilities\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            \n",
    "            # Get the predicted class\n",
    "            _, preds = torch.max(probs, 1)\n",
    "            \n",
    "            # Store predictions\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "\n",
    "    # Convert predictions to numpy array\n",
    "    predictions = np.array(predictions)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEWWWWW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m tensor_dataset \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSchool\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mEE_Y3\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mQ4\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mBAP\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124meeg_thesis_cnn_repo\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mopenvibe\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124minterim\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mopenvibe_dataset_2024-06-08_21-04-15.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Labels are the last column of the tensor dataset\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43mtensor_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# # Shuffle the combined dataset\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# shuffle = True  # Set to True to shuffle the dataset\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# batch_size = 8  # Set batch size as needed\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# combined_dataloader = DataLoader(combined_dataset, batch_size=batch_size, shuffle=shuffle)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\chakr\\Anaconda3\\envs\\eeg_thesis\\lib\\site-packages\\torch\\utils\\data\\dataset.py:209\u001b[0m, in \u001b[0;36mTensorDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[1;32m--> 209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\chakr\\Anaconda3\\envs\\eeg_thesis\\lib\\site-packages\\torch\\utils\\data\\dataset.py:209\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[1;32m--> 209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\u001b[43mtensor\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors)\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for tensor of dimension 1"
     ]
    }
   ],
   "source": [
    "# Load tensor dataset\n",
    "tensor_dataset = torch.load(r\"C:\\School\\EE_Y3\\Q4\\BAP\\eeg_thesis_cnn_repo\\data\\openvibe\\interim\\openvibe_dataset_2024-06-08_21-04-15.pt\")\n",
    "\n",
    "# Labels are the last column of the tensor dataset\n",
    "labels = tensor_dataset[:, :, :, -1]\n",
    "\n",
    "\n",
    "# # Shuffle the combined dataset\n",
    "# shuffle = True  # Set to True to shuffle the dataset\n",
    "# batch_size = 8  # Set batch size as needed\n",
    "# combined_dataloader = DataLoader(combined_dataset, batch_size=batch_size, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TensorDataset' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtensor_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'TensorDataset' object has no attribute 'shape'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chakr\\Anaconda3\\envs\\eeg_thesis\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 34\u001b[0m\n\u001b[0;32m     32\u001b[0m total_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 34\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m data, labels \u001b[38;5;129;01min\u001b[39;00m combined_dataloader:  \u001b[38;5;66;03m# Assuming combined_dataloader is your DataLoader for combined_dataset\u001b[39;00m\n\u001b[0;32m     35\u001b[0m         data, labels \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     36\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m model(data)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# Initialize your model\n",
    "model = Advanced_EEG_MI_CNN_LSTM_Transformer()\n",
    "\n",
    "# Load the trained model weights (assuming they are saved as a .pth file)\n",
    "file = r\"C:\\School\\EE_Y3\\Q4\\BAP\\eeg_thesis_cnn_repo\\models\\Advanced_EEG_MI_CNN_LSTM_Transformer_2024-06-08_16-01-15.pth\"\n",
    "model.load_state_dict(torch.load(file))\n",
    "\n",
    "# Set the device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Define a function to calculate accuracy\n",
    "def calculate_accuracy(outputs, labels):\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    correct = (predicted == labels).sum().item()\n",
    "    total = labels.size(0)\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "# Iterate over the combined dataset\n",
    "total_accuracy = 0.0\n",
    "total_samples = 0\n",
    "with torch.no_grad():\n",
    "    for data, labels in combined_dataloader:  # Assuming combined_dataloader is your DataLoader for combined_dataset\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        outputs = model(data)\n",
    "        batch_accuracy = calculate_accuracy(outputs, labels)\n",
    "        total_accuracy += batch_accuracy * labels.size(0)\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "# Calculate overall accuracy\n",
    "accuracy = total_accuracy / total_samples\n",
    "print(\"Overall accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
