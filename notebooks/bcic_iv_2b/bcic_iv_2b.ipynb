{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'1072': Left Hand MI\n",
    "\n",
    "'276': Right Hand MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import pywt\n",
    "import torch\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epochs_and_labels_bcic_iv_2a(eeg_signal):\n",
    "    \"\"\"\n",
    "    Load the EEG data from a FIF file, extract the epochs and labels, and return them.\n",
    "\n",
    "    Arguments:\n",
    "        - FIF_file (str): Path to the FIF file containing the EEG data.\n",
    "\n",
    "    Returns:\n",
    "        - Epochs (mne.Epochs): EEG epochs extracted from the FIF file.\n",
    "        - Labels (numpy.ndarray): Labels corresponding to the epochs.\n",
    "    \"\"\"\n",
    "    # Get the events from the annotations\n",
    "    events, _ = mne.events_from_annotations(eeg_signal)\n",
    "\n",
    "    event_id = {'left_hand': 1, 'right_hand': 2}\n",
    "\n",
    "    # Epochs start 0s before the trigger and end 0.5s after\n",
    "    epochs = mne.Epochs(eeg_signal, events, event_id, tmin=0, tmax=0.5, baseline=None, preload=True)\n",
    "\n",
    "    # Get the labels of the epochs\n",
    "    labels = epochs.events[:, -1]\n",
    "\n",
    "    # Change the labels to 0 and 1\n",
    "    labels[labels == 2] = 0\n",
    "    labels[labels == 3] = 1\n",
    "    \n",
    "    return epochs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score(epoch):\n",
    "    \"\"\"\n",
    "    Apply z-score normalization to each channel of the EEG data.\n",
    "    \n",
    "    Arguments:\n",
    "        - Epoch (numpy.ndarray): EEG data to be normalized.\n",
    "        \n",
    "    Returns:\n",
    "        - Z-scored epoch (numpy.ndarray): Normalized EEG data.\n",
    "    \"\"\"    \n",
    "    # Apply z-score normalization to each channel, saved in epoch\n",
    "    for i in range(epoch.shape[0]):\n",
    "        channel_epoch = epoch[i, :]\n",
    "        mean = np.mean(channel_epoch)\n",
    "        std = np.std(channel_epoch)\n",
    "        z_scored_epoch = (channel_epoch - mean) / std\n",
    "        epoch[i, :] = z_scored_epoch\n",
    "    \n",
    "    return epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_to_scale(freq, wavelet='morl', sampling_rate=250):\n",
    "    \"\"\"\n",
    "    Convert frequency values to scales for continuous wavelet transform (CWT).\n",
    "\n",
    "    Arguments:\n",
    "        = freq (array): Array of frequency values.\n",
    "        wavelet (str, optional): Type of wavelet to use. Defaults to 'morl'.\n",
    "        sampling_rate (int): Sampling rate of the EEG data. Defaults to 250 Hz.\n",
    "\n",
    "    Returns:\n",
    "        - scales (array): Array of scales corresponding to the input frequencies.\n",
    "    \"\"\"\n",
    "    # For the Morlet wavelet, scales are inversely proportional to frequency\n",
    "    center_freq = pywt.central_frequency(wavelet)\n",
    "    return center_freq / (freq / sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_wavelet_transform(data_norm, wavelet='morl', freq_range=(8, 30), sampling_rate=250):\n",
    "    \"\"\"\n",
    "    Apply wavelet transform to EEG data.\n",
    "    \n",
    "    Arguments:\n",
    "        - data_norm (ndarray): 2D array with shape (n_channels, n_time_points)\n",
    "        - wavelet (str): Wavelet type (default 'morl')\n",
    "        - freq_range (tuple): Frequency range for the CWT (default (8, 30) Hz)\n",
    "        - sampling_rate (int): Sampling rate of the EEG data (default 250 Hz)\n",
    "    \n",
    "    Returns:\n",
    "    ndarray: 3D array with shape (n_channels, n_scales, n_time_points)\n",
    "    \"\"\"\n",
    "    n_channels, n_times = data_norm.shape\n",
    "    # Define scales based on the desired frequency range\n",
    "    scales = frequency_to_scale(np.arange(freq_range[0], freq_range[1]+1), wavelet=wavelet, sampling_rate=sampling_rate)\n",
    "    \n",
    "    coeffs = []\n",
    "    for i in range(n_channels):\n",
    "        # Compute the wavelet transform coefficients\n",
    "        coef, _ = pywt.cwt(data_norm[i], scales=scales, wavelet=wavelet)\n",
    "        coeffs.append(coef)\n",
    "    \n",
    "    # Stack coefficients to form a 3D tensor\n",
    "    coeffs_done = np.stack(coeffs, axis=0)\n",
    "    \n",
    "    return coeffs_done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_wavelet_transform_freq_bands(data_norm, wavelet='morl', freq_ranges=[(8, 13), (14, 30), (31, 50)], sampling_rate=250):\n",
    "    \"\"\"\n",
    "    Apply wavelet transform to EEG data for specified frequency bands.\n",
    "    \n",
    "    Arguments:\n",
    "        - data_norm (ndarray): 2D array with shape (n_channels, n_time_points)\n",
    "        - wavelet (str): Wavelet type (default 'morl')\n",
    "        - freq_ranges (list of tuples): List of frequency ranges for the CWT (default [(8, 13), (14, 30), (31, 50)] Hz)\n",
    "        - sampling_rate (int): Sampling rate of the EEG data (default 250 Hz)\n",
    "    \n",
    "    Returns:\n",
    "        - ndarray: 3D array with shape (n_channels, total_n_scales, n_time_points)\n",
    "    \"\"\"\n",
    "    n_channels, n_times = data_norm.shape\n",
    "    all_coeffs = []\n",
    "\n",
    "    for freq_range in freq_ranges:\n",
    "        # Define scales based on the desired frequency range\n",
    "        scales = frequency_to_scale(np.arange(freq_range[0], freq_range[1] + 1), wavelet=wavelet, sampling_rate=sampling_rate)\n",
    "        \n",
    "        band_coeffs = []\n",
    "        for i in range(n_channels):\n",
    "            # Compute the wavelet transform coefficients for each channel\n",
    "            coef, _ = pywt.cwt(data_norm[i], scales=scales, wavelet=wavelet)\n",
    "            band_coeffs.append(coef)\n",
    "        \n",
    "        # Stack coefficients for the current frequency band along the channel axis\n",
    "        band_coeffs_stacked = np.stack(band_coeffs, axis=0)\n",
    "        all_coeffs.append(band_coeffs_stacked)\n",
    "\n",
    "    # Concatenate coefficients for all frequency bands along the scale axis\n",
    "    coeffs_done = np.concatenate(all_coeffs, axis=1)  # Concatenate along the scale axis\n",
    "\n",
    "    return coeffs_done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bcic_iv_2a_preprocessing(file_path):    \n",
    "    # Suppress `mne` library logging\n",
    "    mne.set_log_level('CRITICAL')\n",
    "\n",
    "    # Load the EEG data\n",
    "    raw = mne.io.read_raw_gdf(file_path, preload=True)\n",
    "\n",
    "    # Filter data between 4 and 35 Hz\n",
    "    filtered_raw = raw.filter(4., 35., fir_design='firwin', skip_by_annotation='edge')\n",
    "\n",
    "    epochs, labels = get_epochs_and_labels_bcic_iv_2a(filtered_raw)\n",
    "\n",
    "    # Empty lists to store the transformed epochs and their labels\n",
    "    all_transformed_epochs = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Process each epoch\n",
    "    for epoch, label in zip(epochs, labels):\n",
    "        # Z-score each epoch\n",
    "        epoch_norm = z_score(epoch)\n",
    "        \n",
    "        # Apply wavelet transformation\n",
    "        epoch_wavelet = apply_wavelet_transform_freq_bands(epoch_norm)\n",
    "        \n",
    "        # Append the transformed epoch and its label to the lists\n",
    "        all_transformed_epochs.append(epoch_wavelet)\n",
    "        all_labels.append(label)\n",
    "        \n",
    "    # Convert the list of all transformed epochs into a single tensor dataset\n",
    "    tensor_dataset = torch.tensor(all_transformed_epochs, dtype=torch.float)\n",
    "\n",
    "    # Convert the list of all labels into a tensor\n",
    "    labels_tensor = torch.tensor(all_labels, dtype=torch.long)\n",
    "    \n",
    "    return tensor_dataset, labels_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bcic_iv_2a_folder_to_tensor(input_folder, output_folder):\n",
    "    all_data = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Loop through each file in the folder\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith('.gdf'):  # Assuming all files are gdf format\n",
    "            file_path = os.path.join(input_folder, filename)\n",
    "            # Apply preprocessing function to each file\n",
    "            tensor_dataset, labels_tensor = bcic_iv_2a_preprocessing(file_path)\n",
    "            all_data.append(tensor_dataset)\n",
    "            all_labels.append(labels_tensor)\n",
    "\n",
    "    # Concatenate all tensors along the first dimension to create a single tensor\n",
    "    all_data = torch.cat(all_data, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    \n",
    "    # Get the current date and time\n",
    "    current_datetime = datetime.now()\n",
    "    \n",
    "    # Format the date and time as a string for the dataset name\n",
    "    time_name = current_datetime.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "    # Make a subfolder for the tensor dataset in the output folder, name it with the current date and time\n",
    "    subfolder = os.path.join(output_folder, time_name)    \n",
    "    \n",
    "    # Save the combined dataset to the subfolder with the specified name\n",
    "    os.makedirs(subfolder, exist_ok=True)\n",
    "    tensor_dataset_file_name = os.path.join(subfolder, f\"dataset_{time_name}.pt\")\n",
    "    torch.save(all_data, tensor_dataset_file_name)\n",
    "    \n",
    "    labels_tensor_file_name = os.path.join(subfolder, f\"labels_{time_name}.pt\")\n",
    "    torch.save(all_labels, labels_tensor_file_name)\n",
    "\n",
    "    return all_data, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chakr\\AppData\\Local\\Temp\\ipykernel_9780\\1693861797.py:30: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:277.)\n",
      "  tensor_dataset = torch.tensor(all_transformed_epochs, dtype=torch.float)\n"
     ]
    }
   ],
   "source": [
    "folder_path = r\"C:\\School\\EE_Y3\\Q4\\BAP\\eeg_thesis_cnn_repo\\data\\bcic_iv_2a\\raw\"\n",
    "output_folder = r\"C:\\School\\EE_Y3\\Q4\\BAP\\eeg_thesis_cnn_repo\\data\\bcic_iv_2a\\processed\"\n",
    "\n",
    "all_data, all_labels = bcic_iv_2a_folder_to_tensor(folder_path, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([506, 25, 43, 126]), torch.Size([506]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.shape, all_labels.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
