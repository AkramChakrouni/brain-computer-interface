{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook takes the data downloaded from https://www.physionet.org/content/eegmmidb/1.0.0/S001/#files-panel and converts it into the baseline dataset of this model in tensor format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ICA filtering needs to be added, for more clean data, which expects to spike up the model accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An enhanced wavelet function will be added to apply the transformation of seperate bands, independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import mne\n",
    "import pywt\n",
    "import torch\n",
    "from datetime import datetime\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_eeg_files(input_folder, output_folder):\n",
    "    \"\"\"\n",
    "    Process all EDF files ending with 'R03', 'R07', or 'R11' in the input folder.\n",
    "    Apply a 5th order IIR Butterworth filter, resample the data to 250 Hz, rename the channels to standard names,\n",
    "    and save each filtered file with a '_filtered' suffix in the output folder.\n",
    "\n",
    "    Arguments:\n",
    "        - Input_folder (str): Path to the folder containing the EDF files to be filtered.\n",
    "        - Output_folder (str): Path to the folder where the filtered files will be saved.\n",
    "        \n",
    "    Returns:\n",
    "        - FIF files: Filtered EEG data files saved in the output folder.\n",
    "        - filtered_files_list (list): List of paths to the filtered files.\n",
    "    \"\"\"\n",
    "    # Ensure the output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # Define the filter parameters\n",
    "    l_freq=8 \n",
    "    h_freq=30\n",
    "    order=5\n",
    "\n",
    "    # Define IIR filter parameters\n",
    "    iir_params = dict(order=order, ftype='butter')\n",
    "    \n",
    "    # List to collect paths of the filtered files\n",
    "    filtered_files_list = []\n",
    "\n",
    "    # Iterate through all subfolders in the output folder\n",
    "    for root, dirs, files in os.walk(input_folder):\n",
    "        for file_name in files:\n",
    "            if file_name.endswith('.edf'):\n",
    "                # Check if file ends with R03, R07, or R11\n",
    "                if file_name.endswith(('R03.edf', 'R07.edf', 'R11.edf')):\n",
    "                    # Construct full file path\n",
    "                    file_path = os.path.join(root, file_name)\n",
    "                    \n",
    "                    # Load the EDF file\n",
    "                    raw = mne.io.read_raw_edf(file_path, preload=True)\n",
    "                    \n",
    "                    # Resample the data to 250 Hz\n",
    "                    raw.resample(250)\n",
    "                    \n",
    "                    # Select specific channels\n",
    "                    raw.pick_channels(['Fp1.', 'Fp2.', 'F2..', 'F4..', 'C3..', 'C4..', 'P3..', 'P4..'], ordered=True)\n",
    "                    \n",
    "                    # Rename the channels\n",
    "                    raw.rename_channels(mapping={'Fp1.': 'FP1', 'Fp2.': 'FP2', 'F2..': 'F2', 'F4..': 'F4', \n",
    "                                                 'C3..': 'C3', 'C4..': 'C4', 'P3..': 'P3', 'P4..': 'P4'})\n",
    "                    \n",
    "                    # Apply the 5th order IIR Butterworth filter\n",
    "                    raw.filter(l_freq=l_freq, h_freq=h_freq, method='iir', iir_params=iir_params)\n",
    "                    \n",
    "                    # Define the output file path\n",
    "                    output_file_name = f\"{os.path.splitext(file_name)[0]}_filtered.fif\"\n",
    "                    output_file_path = os.path.join(output_folder, output_file_name)\n",
    "                    \n",
    "                    # Save the filtered data\n",
    "                    raw.save(output_file_path, overwrite=True)  \n",
    "                    \n",
    "                    # Add the output file path to the list, for return\n",
    "                    filtered_files_list.append(output_file_path)\n",
    "    \n",
    "    # Return the list of filtered file paths\n",
    "    return filtered_files_list     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epochs_and_labels_external(fif_file):\n",
    "    \"\"\"\n",
    "    Load the EEG data from a FIF file, extract the epochs and labels, and return them.\n",
    "\n",
    "    Arguments:\n",
    "        - FIF_file (str): Path to the FIF file containing the EEG data.\n",
    "\n",
    "    Returns:\n",
    "        - Epochs (mne.Epochs): EEG epochs extracted from the FIF file.\n",
    "        - Labels (numpy.ndarray): Labels corresponding to the epochs.\n",
    "    \"\"\"\n",
    "    # Load your EEG data\n",
    "    raw = mne.io.read_raw_fif(fif_file, preload=True)\n",
    "    \n",
    "    # Get the events from the annotations\n",
    "    events, _ = mne.events_from_annotations(raw)\n",
    "\n",
    "    # T1 is left hand, T2 is right hand\n",
    "    event_id = {'T1': 2, 'T2': 3}\n",
    "\n",
    "    # Epochs start 0s before the trigger and end 0.5s after\n",
    "    epochs = mne.Epochs(raw, events, event_id, tmin=0, tmax=0.5, baseline=None, preload=True)\n",
    "\n",
    "    # Get the labels of the epochs\n",
    "    labels = epochs.events[:, -1]\n",
    "\n",
    "    # Change the labels to 0 and 1\n",
    "    labels[labels == 2] = 0\n",
    "    labels[labels == 3] = 1\n",
    "    \n",
    "    return epochs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score(epoch):\n",
    "    \"\"\"\n",
    "    Apply z-score normalization to each channel of the EEG data.\n",
    "    \n",
    "    Arguments:\n",
    "        - Epoch (numpy.ndarray): EEG data to be normalized.\n",
    "        \n",
    "    Returns:\n",
    "        - Z-scored epoch (numpy.ndarray): Normalized EEG data.\n",
    "    \"\"\"    \n",
    "    # Apply z-score normalization to each channel, saved in epoch\n",
    "    for i in range(epoch.shape[0]):\n",
    "        channel_epoch = epoch[i, :]\n",
    "        mean = np.mean(channel_epoch)\n",
    "        std = np.std(channel_epoch)\n",
    "        z_scored_epoch = (channel_epoch - mean) / std\n",
    "        epoch[i, :] = z_scored_epoch\n",
    "    \n",
    "    return epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Channels (8): The first dimension corresponds to the number of EEG channels. Each channel represents a different electrode in the EEG recording setup. In this case, you have 8 channels, so the first dimension of the tensor is 8.\n",
    "\n",
    "Scales (23): The second dimension corresponds to the number of scales used in the Continuous Wavelet Transform (CWT). Scales are inversely related to frequency, and in your case, they are chosen to capture frequencies between 8 Hz and 30 Hz. When we define a range from 8 Hz to 30 Hz and convert these frequencies to scales, we get 23 distinct scales (one for each integer frequency value from 8 to 30, inclusive).\n",
    "\n",
    "Time Points (126): The third dimension corresponds to the number of time points in your EEG data. This is the original length of your time series data for each channel. Since your EEG data has 126 time points, the third dimension of the tensor is 126."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor Shape: (8, 23, 126)\n",
    "\n",
    "- 8: Channels\n",
    "  - Channel 1\n",
    "  - Channel 2\n",
    "  - ...\n",
    "  - Channel 8\n",
    "\n",
    "- 23: Scales (frequency components)\n",
    "  - Scale 1 (corresponds to 8 Hz)\n",
    "  - Scale 2 (corresponds to 9 Hz)\n",
    "  - ...\n",
    "  - Scale 23 (corresponds to 30 Hz)\n",
    "\n",
    "- 126: Time Points\n",
    "  - Time Point 1\n",
    "  - Time Point 2\n",
    "  - ...\n",
    "  - Time Point 126\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_to_scale(freq, wavelet='morl', sampling_rate=250):\n",
    "    \"\"\"\n",
    "    Convert frequency values to scales for continuous wavelet transform (CWT).\n",
    "\n",
    "    Arguments:\n",
    "        = freq (array): Array of frequency values.\n",
    "        wavelet (str, optional): Type of wavelet to use. Defaults to 'morl'.\n",
    "        sampling_rate (int): Sampling rate of the EEG data. Defaults to 250 Hz.\n",
    "\n",
    "    Returns:\n",
    "        - scales (array): Array of scales corresponding to the input frequencies.\n",
    "    \"\"\"\n",
    "    # For the Morlet wavelet, scales are inversely proportional to frequency\n",
    "    center_freq = pywt.central_frequency(wavelet)\n",
    "    return center_freq / (freq / sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_wavelet_transform(data_norm, wavelet='morl', freq_range=(8, 30), sampling_rate=250):\n",
    "    \"\"\"\n",
    "    Apply wavelet transform to EEG data.\n",
    "    \n",
    "    Arguments:\n",
    "        - data_norm (ndarray): 2D array with shape (n_channels, n_time_points)\n",
    "        - wavelet (str): Wavelet type (default 'morl')\n",
    "        - freq_range (tuple): Frequency range for the CWT (default (8, 30) Hz)\n",
    "        - sampling_rate (int): Sampling rate of the EEG data (default 250 Hz)\n",
    "    \n",
    "    Returns:\n",
    "    ndarray: 3D array with shape (n_channels, n_scales, n_time_points)\n",
    "    \"\"\"\n",
    "    n_channels, n_times = data_norm.shape\n",
    "    # Define scales based on the desired frequency range\n",
    "    scales = frequency_to_scale(np.arange(freq_range[0], freq_range[1]+1), wavelet=wavelet, sampling_rate=sampling_rate)\n",
    "    \n",
    "    coeffs = []\n",
    "    for i in range(n_channels):\n",
    "        # Compute the wavelet transform coefficients\n",
    "        coef, _ = pywt.cwt(data_norm[i], scales=scales, wavelet=wavelet)\n",
    "        coeffs.append(coef)\n",
    "    \n",
    "    # Stack coefficients to form a 3D tensor\n",
    "    coeffs_done = np.stack(coeffs, axis=0)\n",
    "    \n",
    "    return coeffs_done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_tensor(input_folder, output_folder_filtered_files, output_folder_tensor_dataset):\n",
    "    \"\"\"\n",
    "    Load the EEG data from a list of FIF files, apply z-score normalization and wavelet transform to each epoch,\n",
    "    and return the transformed epochs and their labels as a combined TensorDataset.\n",
    "\n",
    "    Arguments:\n",
    "        - input_folder (str): Path to the input folder containing the FIF files.\n",
    "        - output_folder_filtered_files (str): Path to the output folder for filtered files.\n",
    "        - output_folder_tensor_dataset (str): Path to the output folder for the combined TensorDataset.\n",
    "\n",
    "    Returns:\n",
    "        - Saves filtered files to the output folder filtered, and the combined TensorDataset to the output folder tensor.\n",
    "    \"\"\"\n",
    "    # Create a list to hold the transformed epochs for all files\n",
    "    all_transformed_epochs = []\n",
    "    \n",
    "    # Create a list to hold the corresponding labels for all epochs\n",
    "    all_labels = []\n",
    "    \n",
    "    # Filter the EEG files\n",
    "    filtered_files = filter_eeg_files(input_folder, output_folder_filtered_files)\n",
    "    \n",
    "    # Process each filtered file\n",
    "    for fif_file in filtered_files:\n",
    "        # Load the EEG data from the FIF file and extract the epochs and labels\n",
    "        epochs, labels = get_epochs_and_labels_external(fif_file)\n",
    "        \n",
    "        # Process each epoch\n",
    "        for epoch, label in zip(epochs, labels):\n",
    "            # Z-score each epoch\n",
    "            epoch_norm = z_score(epoch)\n",
    "            \n",
    "            # Apply wavelet transformation\n",
    "            epoch_wavelet = apply_wavelet_transform(epoch_norm)\n",
    "            \n",
    "            # Append the transformed epoch and its label to the lists\n",
    "            all_transformed_epochs.append(epoch_wavelet)\n",
    "            all_labels.append(label)\n",
    "\n",
    "    # Convert the list of all transformed epochs into a single tensor dataset\n",
    "    tensor_dataset = torch.tensor(all_transformed_epochs, dtype=torch.float)\n",
    "    \n",
    "    # Convert the list of all labels into a tensor\n",
    "    labels_tensor = torch.tensor(all_labels, dtype=torch.long)\n",
    "       \n",
    "    # Get the current date and time\n",
    "    current_datetime = datetime.now()\n",
    "    \n",
    "    # Format the date and time as a string for the dataset name\n",
    "    dataset_name = current_datetime.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    \n",
    "    # Make a subfolder for the tensor dataset in the output folder, name it with the current date and time\n",
    "    subfolder = os.path.join(output_folder_tensor_dataset, dataset_name)    \n",
    "    \n",
    "    # Save the combined dataset to the subfolder with the specified name\n",
    "    os.makedirs(subfolder, exist_ok=True)\n",
    "    tensor_dataset_file_name = os.path.join(subfolder, f\"base_dataset_{dataset_name}.pt\")\n",
    "    torch.save(tensor_dataset, tensor_dataset_file_name)\n",
    "    \n",
    "    labels_tensor_file_name = os.path.join(subfolder, f\"base_labels_{dataset_name}.pt\")\n",
    "    torch.save(labels_tensor, labels_tensor_file_name)\n",
    "    \n",
    "    return tensor_dataset, labels_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = r\"C:\\School\\EE_Y3\\Q4\\BAP\\eeg_thesis_cnn_repo\\data\\external\\raw\"\n",
    "output_folder_filtered_files = r\"C:\\School\\EE_Y3\\Q4\\BAP\\eeg_thesis_cnn_repo\\data\\external\\interim\"\n",
    "output_folder_tensor_dataset = r\"C:\\School\\EE_Y3\\Q4\\BAP\\eeg_thesis_cnn_repo\\data\\base\"\n",
    "tensor_dataset, labels_tensor = file_to_tensor(input_folder, output_folder_filtered_files, output_folder_tensor_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4927, 8, 23, 126])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4927])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_tensor.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
