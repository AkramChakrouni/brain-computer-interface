{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import mne\n",
    "import pywt\n",
    "import torch\n",
    "from datetime import datetime\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_eeg_files(input_folder, output_folder):\n",
    "    \"\"\"\n",
    "    Process all EDF files ending with 'R03', 'R07', or 'R11' in the input folder.\n",
    "    Apply a 5th order IIR Butterworth filter, resample the data to 250 Hz, rename the channels to standard names,\n",
    "    and save each filtered file with a '_filtered' suffix in the output folder.\n",
    "\n",
    "    Arguments:\n",
    "        - Input_folder (str): Path to the folder containing the EDF files to be filtered.\n",
    "        - Output_folder (str): Path to the folder where the filtered files will be saved.\n",
    "        \n",
    "    Returns:\n",
    "        - FIF files: Filtered EEG data files saved in the output folder.\n",
    "        - filtered_files_list (list): List of paths to the filtered files.\n",
    "    \"\"\"\n",
    "    # Ensure the output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # Define the filter parameters\n",
    "    l_freq=8 \n",
    "    h_freq=30\n",
    "    order=5\n",
    "\n",
    "    # Define IIR filter parameters\n",
    "    iir_params = dict(order=order, ftype='butter')\n",
    "    \n",
    "    # List to collect paths of the filtered files\n",
    "    filtered_files_list = []\n",
    "\n",
    "    # Iterate through all subfolders in the output folder\n",
    "    for root, _, files in os.walk(input_folder):\n",
    "        for file_name in files:\n",
    "            if file_name.endswith('.edf'):\n",
    "                # Construct full file path\n",
    "                file_path = os.path.join(root, file_name)\n",
    "                \n",
    "                # Load the EDF file\n",
    "                raw = mne.io.read_raw_edf(file_path, preload=True)                \n",
    "                \n",
    "                # Apply the 5th order IIR Butterworth filter\n",
    "                raw.filter(l_freq=l_freq, h_freq=h_freq, method='iir', iir_params=iir_params)\n",
    "                \n",
    "                # Define the output file path\n",
    "                output_file_name = f\"{os.path.splitext(file_name)[0]}_filtered.fif\"\n",
    "                output_file_path = os.path.join(output_folder, output_file_name)\n",
    "                \n",
    "                # Save the filtered data\n",
    "                raw.save(output_file_path, overwrite=True)  \n",
    "                \n",
    "                # Add the output file path to the list, for return\n",
    "                filtered_files_list.append(output_file_path)\n",
    "    \n",
    "    # Return the list of filtered file paths\n",
    "    return filtered_files_list     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epochs_and_labels_openvibe(fif_file):\n",
    "    \"\"\"\n",
    "    Load the EEG data from a FIF file, extract the epochs and labels, and return them.\n",
    "\n",
    "    Arguments:\n",
    "        - FIF_file (str): Path to the FIF file containing the EEG data.\n",
    "\n",
    "    Returns:\n",
    "        - Epochs (mne.Epochs): EEG epochs extracted from the FIF file.\n",
    "        - Labels (numpy.ndarray): Labels corresponding to the epochs.\n",
    "    \"\"\"\n",
    "    # Load your EEG data\n",
    "    raw = mne.io.read_raw_fif(fif_file, preload=True)\n",
    "    \n",
    "    # Get the events from the annotations\n",
    "    events, _ = mne.events_from_annotations(raw)\n",
    "\n",
    "    # T1 is left hand, T2 is right hand\n",
    "    event_id = {'OVTK_GDF_Left': 5, 'OVTK_GDF_Right': 6}\n",
    "\n",
    "    # Epochs start 0s before the trigger and end 0.5s after\n",
    "    epochs = mne.Epochs(raw, events, event_id, tmin=0, tmax=0.5, baseline=None, preload=True)\n",
    "\n",
    "    # Get the labels of the epochs\n",
    "    labels = epochs.events[:, -1]\n",
    "\n",
    "    # Change the labels to 0 and 1\n",
    "    labels[labels == 5] = 0\n",
    "    labels[labels == 6] = 1\n",
    "    \n",
    "    return epochs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score(epoch):\n",
    "    \"\"\"\n",
    "    Apply z-score normalization to each channel of the EEG data.\n",
    "    \n",
    "    Arguments:\n",
    "        - Epoch (numpy.ndarray): EEG data to be normalized.\n",
    "        \n",
    "    Returns:\n",
    "        - Z-scored epoch (numpy.ndarray): Normalized EEG data.\n",
    "    \"\"\"    \n",
    "    # Apply z-score normalization to each channel, saved in epoch\n",
    "    for i in range(epoch.shape[0]):\n",
    "        channel_epoch = epoch[i, :]\n",
    "        mean = np.mean(channel_epoch)\n",
    "        std = np.std(channel_epoch)\n",
    "        z_scored_epoch = (channel_epoch - mean) / std\n",
    "        epoch[i, :] = z_scored_epoch\n",
    "    \n",
    "    return epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_to_scale(freq, wavelet='morl', sampling_rate=250):\n",
    "    \"\"\"\n",
    "    Convert frequency values to scales for continuous wavelet transform (CWT).\n",
    "\n",
    "    Arguments:\n",
    "        = freq (array): Array of frequency values.\n",
    "        wavelet (str, optional): Type of wavelet to use. Defaults to 'morl'.\n",
    "        sampling_rate (int): Sampling rate of the EEG data. Defaults to 250 Hz.\n",
    "\n",
    "    Returns:\n",
    "        - scales (array): Array of scales corresponding to the input frequencies.\n",
    "    \"\"\"\n",
    "    # For the Morlet wavelet, scales are inversely proportional to frequency\n",
    "    center_freq = pywt.central_frequency(wavelet)\n",
    "    return center_freq / (freq / sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_wavelet_transform(data_norm, wavelet='morl', freq_range=(8, 30), sampling_rate=250):\n",
    "    \"\"\"\n",
    "    Apply wavelet transform to EEG data.\n",
    "    \n",
    "    Arguments:\n",
    "        - data_norm (ndarray): 2D array with shape (n_channels, n_time_points)\n",
    "        - wavelet (str): Wavelet type (default 'morl')\n",
    "        - freq_range (tuple): Frequency range for the CWT (default (8, 30) Hz)\n",
    "        - sampling_rate (int): Sampling rate of the EEG data (default 250 Hz)\n",
    "    \n",
    "    Returns:\n",
    "    ndarray: 3D array with shape (n_channels, n_scales, n_time_points)\n",
    "    \"\"\"\n",
    "    n_channels, n_times = data_norm.shape\n",
    "    # Define scales based on the desired frequency range\n",
    "    scales = frequency_to_scale(np.arange(freq_range[0], freq_range[1]+1), wavelet=wavelet, sampling_rate=sampling_rate)\n",
    "    \n",
    "    coeffs = []\n",
    "    for i in range(n_channels):\n",
    "        # Compute the wavelet transform coefficients\n",
    "        coef, _ = pywt.cwt(data_norm[i], scales=scales, wavelet=wavelet)\n",
    "        coeffs.append(coef)\n",
    "    \n",
    "    # Stack coefficients to form a 3D tensor\n",
    "    coeffs_done = np.stack(coeffs, axis=0)\n",
    "    \n",
    "    return coeffs_done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_tensor(input_folder, output_folder_filtered_files, output_folder_tensor_dataset):\n",
    "    \"\"\"\n",
    "    Load the EEG data from a list of FIF files, apply z-score normalization and wavelet transform to each epoch,\n",
    "    and return the transformed epochs and their labels as a combined TensorDataset.\n",
    "\n",
    "    Arguments:\n",
    "        - input_folder (str): Path to the input folder containing the FIF files.\n",
    "        - output_folder_filtered_files (str): Path to the output folder for filtered files.\n",
    "        - output_folder_tensor_dataset (str): Path to the output folder for the combined TensorDataset.\n",
    "\n",
    "    Returns:\n",
    "        - Saves filtered files to the output folder filtered, and the combined TensorDataset to the output folder tensor.\n",
    "    \"\"\"\n",
    "    # Create a list to hold the transformed epochs for all files\n",
    "    all_transformed_epochs = []\n",
    "    \n",
    "    # Create a list to hold the corresponding labels for all epochs\n",
    "    all_labels = []\n",
    "    \n",
    "    # Filter the EEG files\n",
    "    filtered_files = filter_eeg_files(input_folder, output_folder_filtered_files)\n",
    "    \n",
    "    # Process each filtered file\n",
    "    for fif_file in filtered_files:\n",
    "        # Load the EEG data from the FIF file and extract the epochs and labels\n",
    "        epochs, labels = get_epochs_and_labels_openvibe(fif_file)\n",
    "        \n",
    "        # Process each epoch\n",
    "        for epoch, label in zip(epochs, labels):\n",
    "            # Z-score each epoch\n",
    "            epoch_norm = z_score(epoch)\n",
    "            \n",
    "            # Apply wavelet transformation\n",
    "            epoch_wavelet = apply_wavelet_transform(epoch_norm)\n",
    "            \n",
    "            # Append the transformed epoch and its label to the lists\n",
    "            all_transformed_epochs.append(epoch_wavelet)\n",
    "            all_labels.append(label)\n",
    "\n",
    "    # Convert the list of all transformed epochs into a single tensor dataset\n",
    "    tensor_dataset = torch.tensor(all_transformed_epochs, dtype=torch.float)\n",
    "    \n",
    "    # Convert the list of all labels into a tensor\n",
    "    labels_tensor = torch.tensor(all_labels, dtype=torch.long)\n",
    "    \n",
    "    # Combine the tensor dataset and labels tensor into a TensorDataset\n",
    "    dataset = TensorDataset(tensor_dataset, labels_tensor)\n",
    "    \n",
    "    # Get the current date and time\n",
    "    current_datetime = datetime.now()\n",
    "    \n",
    "    # Format the date and time as a string for the dataset name\n",
    "    dataset_name = current_datetime.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    \n",
    "    # Save the combined dataset to the output folder with the specified name\n",
    "    output_file = os.path.join(output_folder_tensor_dataset, f\"baseline_dataset_{dataset_name}.pt\")\n",
    "    torch.save(dataset, output_file)\n",
    "    \n",
    "    return tensor_dataset, labels_tensor, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\School\\EE_Y3\\Q4\\BAP\\eeg_thesis_cnn_repo\\data\\openvibe\\raw\\record-[2024.05.29-15.06.48]_FILTERED.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 36749  =      0.000 ...   146.996 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 8 - 30 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 20 (effective, after forward-backward)\n",
      "- Cutoffs at 8.00, 30.00 Hz: -6.02, -6.02 dB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chakr\\AppData\\Local\\Temp\\ipykernel_1452\\323321866.py:37: RuntimeWarning: Invalid patient information \n",
      "  raw = mne.io.read_raw_edf(file_path, preload=True)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'output_file_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m output_folder_filtered_files \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSchool\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mEE_Y3\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mQ4\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mBAP\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124meeg_thesis_cnn_repo\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mopenvibe\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mprocessed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m output_folder_tensor_dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSchool\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mEE_Y3\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mQ4\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mBAP\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124meeg_thesis_cnn_repo\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mopenvibe\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124minterim\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m tensor_dataset, labels_tensor, dataset \u001b[38;5;241m=\u001b[39m \u001b[43mfile_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_folder\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 21\u001b[0m, in \u001b[0;36mfile_to_tensor\u001b[1;34m(input_folder)\u001b[0m\n\u001b[0;32m     18\u001b[0m all_labels \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Filter the EEG files\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m filtered_files \u001b[38;5;241m=\u001b[39m \u001b[43mfilter_eeg_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_folder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Process each filtered file\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fif_file \u001b[38;5;129;01min\u001b[39;00m filtered_files:\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;66;03m# Load the EEG data from the FIF file and extract the epochs and labels\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[8], line 50\u001b[0m, in \u001b[0;36mfilter_eeg_files\u001b[1;34m(input_folder)\u001b[0m\n\u001b[0;32m     40\u001b[0m             raw\u001b[38;5;241m.\u001b[39mfilter(l_freq\u001b[38;5;241m=\u001b[39ml_freq, h_freq\u001b[38;5;241m=\u001b[39mh_freq, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miir\u001b[39m\u001b[38;5;124m'\u001b[39m, iir_params\u001b[38;5;241m=\u001b[39miir_params)\n\u001b[0;32m     42\u001b[0m             \u001b[38;5;66;03m# # Define the output file path\u001b[39;00m\n\u001b[0;32m     43\u001b[0m             \u001b[38;5;66;03m# output_file_name = f\"{os.path.splitext(file_name)[0]}_filtered.fif\"\u001b[39;00m\n\u001b[0;32m     44\u001b[0m             \u001b[38;5;66;03m# output_file_path = os.path.join(output_folder, output_file_name)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     48\u001b[0m             \n\u001b[0;32m     49\u001b[0m             \u001b[38;5;66;03m# Add the output file path to the list, for return\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m             filtered_files_list\u001b[38;5;241m.\u001b[39mappend(\u001b[43moutput_file_path\u001b[49m)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Return the list of filtered file paths\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m filtered_files_list\n",
      "\u001b[1;31mNameError\u001b[0m: name 'output_file_path' is not defined"
     ]
    }
   ],
   "source": [
    "input_folder = r\"C:\\School\\EE_Y3\\Q4\\BAP\\eeg_thesis_cnn_repo\\data\\openvibe\\raw\"\n",
    "output_folder_filtered_files = r\"C:\\School\\EE_Y3\\Q4\\BAP\\eeg_thesis_cnn_repo\\data\\openvibe\\processed\"\n",
    "output_folder_tensor_dataset = r\"C:\\School\\EE_Y3\\Q4\\BAP\\eeg_thesis_cnn_repo\\data\\openvibe\\interim\"\n",
    "tensor_dataset, labels_tensor, dataset = file_to_tensor(input_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50, 8, 23, 126]),\n",
       " torch.Size([50]),\n",
       " torch.Size([50, 8, 23, 126]),\n",
       " torch.Size([50]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_dataset.shape, labels_tensor.shape, dataset.tensors[0].shape, dataset.tensors[1].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
