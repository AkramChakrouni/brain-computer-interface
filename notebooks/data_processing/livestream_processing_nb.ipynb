{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.signal import butter, filtfilt\n",
    "import torch\n",
    "import pywt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_df(file_path):\n",
    "    # Read the csv file\n",
    "    df_in = pd.read_csv(file_path)\n",
    "\n",
    "    # Get the header row\n",
    "    header_row = list(df_in.columns)\n",
    "\n",
    "    # Convert the header row to integer values\n",
    "    header_row = list(map(int, header_row))\n",
    "\n",
    "    # Create a DataFrame from the header row\n",
    "    header_df = pd.DataFrame([header_row], columns=df_in.columns)\n",
    "\n",
    "    # Concatenate the header row with the original DataFrame\n",
    "    df_imm = pd.concat([header_df, df_in], ignore_index=True)\n",
    "\n",
    "    # Reset column names\n",
    "    df_imm.columns = range(df_imm.shape[1])\n",
    "\n",
    "    # Remove the first column\n",
    "    df_imm = df_imm.drop(0, axis=1)\n",
    "\n",
    "    df_out = df_imm.T\n",
    "    \n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score(epoch):    \n",
    "    # Apply z-score normalization to each channel, saved in epoch\n",
    "    for i in range(epoch.shape[0]):\n",
    "        channel_epoch = epoch.iloc[i]\n",
    "        mean = np.mean(channel_epoch)\n",
    "        std = np.std(channel_epoch)\n",
    "        z_scored_epoch = (channel_epoch - mean) / std\n",
    "        epoch.iloc[i] = z_scored_epoch\n",
    "    \n",
    "    return epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_to_scale(freq, wavelet='morl', sampling_rate=250):\n",
    "    # For the Morlet wavelet, scales are inversely proportional to frequency\n",
    "    center_freq = pywt.central_frequency(wavelet)\n",
    "    return center_freq / (freq / sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_wavelet_transform(data_norm, wavelet='morl', freq_range=(8, 30), sampling_rate=250):\n",
    "    \"\"\"\n",
    "    Apply wavelet transform to EEG data.\n",
    "    \n",
    "    Parameters:\n",
    "    data_norm (ndarray): 2D array with shape (channels, time_points)\n",
    "    wavelet (str): Wavelet type (default 'morl')\n",
    "    freq_range (tuple): Frequency range for the CWT (default (8, 30) Hz)\n",
    "    sampling_rate (int): Sampling rate of the EEG data (default 250 Hz)\n",
    "    \n",
    "    Returns:\n",
    "    ndarray: 3D array with shape (channels, scales, time_points)\n",
    "    \"\"\"\n",
    "    n_channels, n_times = data_norm.shape\n",
    "    # Define scales based on the desired frequency range\n",
    "    scales = frequency_to_scale(np.arange(freq_range[0], freq_range[1]+1), wavelet=wavelet, sampling_rate=sampling_rate)\n",
    "    \n",
    "    coeffs = []\n",
    "    for i in range(n_channels):\n",
    "        # Compute the wavelet transform coefficients\n",
    "        coef, _ = pywt.cwt(data_norm.iloc[i], scales=scales, wavelet=wavelet)\n",
    "        coeffs.append(coef)\n",
    "    \n",
    "    # Stack coefficients to form a 3D tensor\n",
    "    coeffs_done = np.stack(coeffs, axis=0)\n",
    "    \n",
    "    return coeffs_done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_bandpass_filter(signal, b, a):\n",
    "    return filtfilt(b, a, signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_livestreamed_signal(file_path):\n",
    "    # Load the data, in dataframe format\n",
    "    data_raw = csv_to_df(file_path)\n",
    "    \n",
    "    # Filter parameters\n",
    "    l_freq = 8\n",
    "    h_freq = 30\n",
    "    order = 5\n",
    "    fs = 250\n",
    "\n",
    "    nyquist = 0.5 * fs\n",
    "    low = l_freq / nyquist\n",
    "    high = h_freq / nyquist\n",
    "\n",
    "    # Calculate filter coefficients\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    \n",
    "    # Apply the filter to each row independently\n",
    "    for i in range(data_raw.shape[0]):\n",
    "        data_raw.iloc[i] = apply_bandpass_filter(data_raw.iloc[i], b, a)\n",
    "        \n",
    "    # Convert filtered data back to DataFrame\n",
    "    data_filtered = pd.DataFrame(data_raw)\n",
    "    \n",
    "    # Split data into segments of 0.5 seconds, for epoching\n",
    "    epoch_size = int(fs * 0.5)  # Number of samples in 0.5 seconds\n",
    "    epochs = [data_filtered.iloc[:, i:i+epoch_size] for i in range(0, len(data_filtered.columns), epoch_size)]\n",
    "    \n",
    "    # Create an empty list to store the transformed epochs\n",
    "    transformed_epochs = []\n",
    "    \n",
    "    # Z-score normalization and wavelet transform for each segment and stack them into a tensor (4D array), \n",
    "    # Loop through each epoch\n",
    "    for epoch in epochs:\n",
    "        # Z-score each epoch\n",
    "        epoch_norm = z_score(epoch)\n",
    "        \n",
    "        # Apply wavelet transformation\n",
    "        wavelet_tensor = apply_wavelet_transform(epoch_norm)\n",
    "        \n",
    "        # Append the transformed epoch to the list\n",
    "        transformed_epochs.append(wavelet_tensor)\n",
    "        \n",
    "        \n",
    "    # Convert the list of epochs into a tensor dataset\n",
    "    livestreamed_tensor = torch.tensor(transformed_epochs, dtype=torch.float32)  # Ensure the tensor is float32\n",
    "     \n",
    "    return livestreamed_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chakr\\AppData\\Local\\Temp\\ipykernel_9672\\1123883349.py:46: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:277.)\n",
      "  livestreamed_tensor = torch.tensor(transformed_epochs, dtype=torch.float32)  # Ensure the tensor is float32\n"
     ]
    }
   ],
   "source": [
    "input_file_path = r\"C:\\School\\EE_Y3\\Q4\\BAP\\eeg_thesis_cnn_repo\\data\\vue\\lefts_adnane.csv\"\n",
    "data_to_predict = processing_livestreamed_signal(input_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 8, 23, 125])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_predict.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
