{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import numpy as np\n",
    "import os\n",
    "import mne\n",
    "import torch.nn.functional as F\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.signal import butter, filtfilt\n",
    "import torch\n",
    "import pywt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_from_csv(file_path):\n",
    "    # Read the csv file\n",
    "    df_in = pd.read_csv(file_path)\n",
    "\n",
    "    # Get the header row\n",
    "    header_row = list(df_in.columns)\n",
    "\n",
    "    # Convert the header row to integer values\n",
    "    header_row = list(map(int, header_row))\n",
    "\n",
    "    # Create a DataFrame from the header row\n",
    "    header_df = pd.DataFrame([header_row], columns=df_in.columns)\n",
    "\n",
    "    # Concatenate the header row with the original DataFrame\n",
    "    df_imm = pd.concat([header_df, df_in], ignore_index=True)\n",
    "\n",
    "    # Reset column names\n",
    "    df_imm.columns = range(df_imm.shape[1])\n",
    "\n",
    "    # Remove the first column\n",
    "    df_imm = df_imm.drop(0, axis=1)\n",
    "\n",
    "    df_out = df_imm.T\n",
    "    \n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score(epoch):    \n",
    "    # Apply z-score normalization to each channel, saved in epoch\n",
    "    for i in range(epoch.shape[0]):\n",
    "        channel_epoch = epoch.iloc[i]\n",
    "        mean = np.mean(channel_epoch)\n",
    "        std = np.std(channel_epoch)\n",
    "        z_scored_epoch = (channel_epoch - mean) / std\n",
    "        epoch.iloc[i] = z_scored_epoch\n",
    "    \n",
    "    return epoch\n",
    "\n",
    "def frequency_to_scale(freq, wavelet='morl', sampling_rate=250):\n",
    "    # For the Morlet wavelet, scales are inversely proportional to frequency\n",
    "    center_freq = pywt.central_frequency(wavelet)\n",
    "    return center_freq / (freq / sampling_rate)\n",
    "\n",
    "def apply_wavelet_transform(data_norm, wavelet='morl', freq_range=(8, 30), sampling_rate=250):\n",
    "    \"\"\"\n",
    "    Apply wavelet transform to EEG data.\n",
    "    \n",
    "    Parameters:\n",
    "    data_norm (ndarray): 2D array with shape (channels, time_points)\n",
    "    wavelet (str): Wavelet type (default 'morl')\n",
    "    freq_range (tuple): Frequency range for the CWT (default (8, 30) Hz)\n",
    "    sampling_rate (int): Sampling rate of the EEG data (default 250 Hz)\n",
    "    \n",
    "    Returns:\n",
    "    ndarray: 3D array with shape (channels, scales, time_points)\n",
    "    \"\"\"\n",
    "    n_channels, n_times = data_norm.shape\n",
    "    # Define scales based on the desired frequency range\n",
    "    scales = frequency_to_scale(np.arange(freq_range[0], freq_range[1]+1), wavelet=wavelet, sampling_rate=sampling_rate)\n",
    "    \n",
    "    coeffs = []\n",
    "    for i in range(n_channels):\n",
    "        # Compute the wavelet transform coefficients\n",
    "        coef, _ = pywt.cwt(data_norm.iloc[i], scales=scales, wavelet=wavelet)\n",
    "        coeffs.append(coef)\n",
    "    \n",
    "    # Stack coefficients to form a 3D tensor\n",
    "    coeffs_done = np.stack(coeffs, axis=0)\n",
    "    \n",
    "    return coeffs_done\n",
    "\n",
    "def apply_bandpass_filter(signal, b, a):\n",
    "    return filtfilt(b, a, signal)\n",
    "\n",
    "def filtering_raw_signal(file_path):\n",
    "    # Load the data, in dataframe format\n",
    "    data_raw = df_from_csv(file_path)\n",
    "    \n",
    "    # Filter parameters\n",
    "    l_freq = 8\n",
    "    h_freq = 30\n",
    "    order = 5\n",
    "    fs = 250\n",
    "\n",
    "    nyquist = 0.5 * fs\n",
    "    low = l_freq / nyquist\n",
    "    high = h_freq / nyquist\n",
    "\n",
    "    # Calculate filter coefficients\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    \n",
    "    # Apply the filter to each row independently\n",
    "    for i in range(data_raw.shape[0]):\n",
    "        data_raw.iloc[i] = apply_bandpass_filter(data_raw.iloc[i], b, a)\n",
    "        \n",
    "    # Convert filtered data back to DataFrame\n",
    "    data_filtered = pd.DataFrame(data_raw)\n",
    "    \n",
    "    # Split data into segments of 0.5 seconds, for epoching\n",
    "    epoch_size = int(fs * 0.5)  # Number of samples in 0.5 seconds\n",
    "    epochs = [data_filtered.iloc[:, i:i+epoch_size] for i in range(0, len(data_filtered.columns), epoch_size)]\n",
    "    \n",
    "    # Create an empty list to store the transformed epochs\n",
    "    transformed_epochs = []\n",
    "    \n",
    "    # Z-score normalization and wavelet transform for each segment and stack them into a tensor (4D array), \n",
    "    # Loop through each epoch\n",
    "    for epoch in epochs:\n",
    "        # Z-score each epoch\n",
    "        epoch_norm = z_score(epoch)\n",
    "        \n",
    "        # # Apply wavelet transformation\n",
    "        wavelet_tensor = apply_wavelet_transform(epoch_norm)\n",
    "        \n",
    "        # Append the transformed epoch to the list\n",
    "        transformed_epochs.append(wavelet_tensor)\n",
    "        \n",
    "        \n",
    "    # Convert the list of epochs into a tensor dataset\n",
    "    tensor_dataset = torch.tensor(transformed_epochs, dtype=torch.float32)  # Ensure the tensor is float32\n",
    "     \n",
    "    return tensor_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chakr\\AppData\\Local\\Temp\\ipykernel_15544\\858416405.py:93: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:277.)\n",
      "  tensor_dataset = torch.tensor(transformed_epochs, dtype=torch.float32)  # Ensure the tensor is float32\n"
     ]
    }
   ],
   "source": [
    "a = r\"C:\\School\\EE_Y3\\Q4\\BAP\\eeg_thesis_cnn_repo\\data\\vue\\lefts_adnane.csv\"\n",
    "left_tensor = filtering_raw_signal(a)\n",
    "\n",
    "b = r\"C:\\School\\EE_Y3\\Q4\\BAP\\eeg_thesis_cnn_repo\\data\\vue\\rights_adnane.csv\"\n",
    "right_tensor = filtering_raw_signal(b)\n",
    "\n",
    "# Array of 50 zeros\n",
    "zeross = np.zeros(50)\n",
    "\n",
    "# Array of 50 ones\n",
    "oness = np.ones(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, ConcatDataset, DataLoader\n",
    "\n",
    "# Assuming you have two tensors: tensor1 and tensor2, and their corresponding label arrays: labels1 and labels2\n",
    "tensor1 = left_tensor  # Your first tensor\n",
    "tensor2 = right_tensor  # Your second tensor\n",
    "labels1 = zeross  # Labels corresponding to tensor1\n",
    "labels2 = oness  # Labels corresponding to tensor2\n",
    "\n",
    "# Convert label arrays to tensors\n",
    "labels1_tensor = torch.tensor(labels1)\n",
    "labels2_tensor = torch.tensor(labels2)\n",
    "\n",
    "# In long format\n",
    "labels1_tensor = torch.tensor(labels1, dtype=torch.float32).to(torch.long)\n",
    "labels2_tensor = torch.tensor(labels2, dtype=torch.float32).to(torch.long)\n",
    "labels = torch.cat((labels1_tensor, labels2_tensor))\n",
    "\n",
    "# Create datasets from tensors and labels\n",
    "dataset1 = TensorDataset(tensor1, labels1_tensor)\n",
    "dataset2 = TensorDataset(tensor2, labels2_tensor)\n",
    "\n",
    "# Concatenate the datasets\n",
    "combined_dataset = ConcatDataset([dataset1, dataset2])\n",
    "\n",
    "train_size = int(0.8 * len(combined_dataset))\n",
    "val_size = len(combined_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(combined_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Advanced_EEG_MI_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Advanced_EEG_MI_CNN, self).__init__()\n",
    "        # First convolutional layer with Batch Normalization and ReLU activation\n",
    "        self.conv1 = nn.Conv2d(in_channels=8, out_channels=32, kernel_size=(3, 3), padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        \n",
    "        # Second convolutional layer with Batch Normalization and ReLU activation\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        \n",
    "        # Third convolutional layer with Batch Normalization and ReLU activation\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3), padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool3 = nn.AvgPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        \n",
    "        # Dropout layer to prevent overfitting\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(128 * 2 * 15, 256)  # Adjust based on final output size after conv layers\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64, 2)  # Assuming 2 classes for binary classification\n",
    "\n",
    "    def _forward_conv_layers(self, x):\n",
    "        # Forward pass through the first convolutional layer\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        # Forward pass through the second convolutional layer\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "        # Forward pass through the third convolutional layer\n",
    "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through the convolutional layers\n",
    "        x = self._forward_conv_layers(x)\n",
    "        # Flatten the tensor to feed into fully connected layers\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # Forward pass through the first fully connected layer with ReLU and dropout\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        # Forward pass through the second fully connected layer with ReLU\n",
    "        x = F.relu(self.fc2(x))\n",
    "        # Output layer\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Advanced_EEG_MI_CNN_LSTM_Transformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Advanced_EEG_MI_CNN_LSTM_Transformer, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=8, out_channels=32, kernel_size=(3, 3), padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3), padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool3 = nn.AvgPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        \n",
    "        # LSTM layer\n",
    "        self.lstm = nn.LSTM(input_size=128*2*15, hidden_size=128, num_layers=1, batch_first=True)\n",
    "        \n",
    "        # Transformer layer\n",
    "        self.transformer_encoder_layer = nn.TransformerEncoderLayer(d_model=128, nhead=8)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.transformer_encoder_layer, num_layers=1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(128, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64, 2)\n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        \n",
    "    def _forward_conv_layers(self, x):\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        # Forward pass through convolutional layers\n",
    "        x = self._forward_conv_layers(x)\n",
    "        \n",
    "        # Flatten for LSTM\n",
    "        x = x.view(batch_size, -1, 128*2*15)\n",
    "        \n",
    "        # Forward pass through LSTM\n",
    "        x, (hn, cn) = self.lstm(x)\n",
    "        \n",
    "        # Transformer encoding\n",
    "        x = self.transformer_encoder(x)\n",
    "        \n",
    "        # Take the output from the last sequence step for classification\n",
    "        x = x[:, -1, :]\n",
    "        \n",
    "        # Forward pass through fully connected layers\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 0.7346\n",
      "Validation Loss: 0.6893, Validation Accuracy: 0.5500\n",
      "Epoch 2/50, Loss: 0.6907\n",
      "Validation Loss: 0.6926, Validation Accuracy: 0.5000\n",
      "Epoch 3/50, Loss: 0.6817\n",
      "Validation Loss: 0.6813, Validation Accuracy: 0.5500\n",
      "Epoch 4/50, Loss: 0.5504\n",
      "Validation Loss: 0.6468, Validation Accuracy: 0.7000\n",
      "Epoch 5/50, Loss: 0.3380\n",
      "Validation Loss: 0.9555, Validation Accuracy: 0.6000\n",
      "Epoch 6/50, Loss: 0.0833\n",
      "Validation Loss: 1.0555, Validation Accuracy: 0.7500\n",
      "Epoch 7/50, Loss: 0.5971\n",
      "Validation Loss: 0.9994, Validation Accuracy: 0.7000\n",
      "Epoch 8/50, Loss: 0.3674\n",
      "Validation Loss: 0.6293, Validation Accuracy: 0.6500\n",
      "Epoch 9/50, Loss: 0.4005\n",
      "Validation Loss: 0.8803, Validation Accuracy: 0.7500\n",
      "Epoch 10/50, Loss: 0.1678\n",
      "Validation Loss: 0.7189, Validation Accuracy: 0.8000\n",
      "Epoch 11/50, Loss: 0.1201\n",
      "Validation Loss: 1.0590, Validation Accuracy: 0.7500\n",
      "Epoch 12/50, Loss: 0.0928\n",
      "Validation Loss: 0.9076, Validation Accuracy: 0.7000\n",
      "Epoch 13/50, Loss: 0.2321\n",
      "Validation Loss: 1.0860, Validation Accuracy: 0.7500\n",
      "Epoch 14/50, Loss: 0.3595\n",
      "Validation Loss: 0.7811, Validation Accuracy: 0.6500\n",
      "Epoch 15/50, Loss: 0.1526\n",
      "Validation Loss: 1.0459, Validation Accuracy: 0.7500\n",
      "Epoch 16/50, Loss: 0.0287\n",
      "Validation Loss: 1.5669, Validation Accuracy: 0.7000\n",
      "Epoch 17/50, Loss: 0.0376\n",
      "Validation Loss: 1.6200, Validation Accuracy: 0.7000\n",
      "Epoch 18/50, Loss: 0.5221\n",
      "Validation Loss: 1.4004, Validation Accuracy: 0.7000\n",
      "Epoch 19/50, Loss: 0.3290\n",
      "Validation Loss: 0.6170, Validation Accuracy: 0.7500\n",
      "Epoch 20/50, Loss: 0.2476\n",
      "Validation Loss: 0.6988, Validation Accuracy: 0.7500\n",
      "Epoch 21/50, Loss: 0.1058\n",
      "Validation Loss: 0.9455, Validation Accuracy: 0.7000\n",
      "Epoch 22/50, Loss: 0.1327\n",
      "Validation Loss: 0.9419, Validation Accuracy: 0.8000\n",
      "Epoch 23/50, Loss: 0.0914\n",
      "Validation Loss: 1.0322, Validation Accuracy: 0.7500\n",
      "Epoch 24/50, Loss: 0.0277\n",
      "Validation Loss: 1.7479, Validation Accuracy: 0.6000\n",
      "Epoch 25/50, Loss: 0.0656\n",
      "Validation Loss: 2.1178, Validation Accuracy: 0.6000\n",
      "Epoch 26/50, Loss: 0.0235\n",
      "Validation Loss: 1.3232, Validation Accuracy: 0.7000\n",
      "Epoch 27/50, Loss: 0.0355\n",
      "Validation Loss: 1.6932, Validation Accuracy: 0.7000\n",
      "Epoch 28/50, Loss: 0.0097\n",
      "Validation Loss: 1.8479, Validation Accuracy: 0.6500\n",
      "Epoch 29/50, Loss: 0.0043\n",
      "Validation Loss: 1.8444, Validation Accuracy: 0.6500\n",
      "Epoch 30/50, Loss: 0.0012\n",
      "Validation Loss: 2.0305, Validation Accuracy: 0.6500\n",
      "Epoch 31/50, Loss: 0.2475\n",
      "Validation Loss: 1.3218, Validation Accuracy: 0.7500\n",
      "Epoch 32/50, Loss: 0.1413\n",
      "Validation Loss: 1.3283, Validation Accuracy: 0.6000\n",
      "Epoch 33/50, Loss: 0.1527\n",
      "Validation Loss: 1.1524, Validation Accuracy: 0.7000\n",
      "Epoch 34/50, Loss: 0.0628\n",
      "Validation Loss: 1.3453, Validation Accuracy: 0.7000\n",
      "Epoch 35/50, Loss: 0.0246\n",
      "Validation Loss: 1.7964, Validation Accuracy: 0.7500\n",
      "Epoch 36/50, Loss: 0.0513\n",
      "Validation Loss: 1.6606, Validation Accuracy: 0.8000\n",
      "Epoch 37/50, Loss: 0.1973\n",
      "Validation Loss: 3.2343, Validation Accuracy: 0.5500\n",
      "Epoch 38/50, Loss: 0.0042\n",
      "Validation Loss: 1.7792, Validation Accuracy: 0.7000\n",
      "Epoch 39/50, Loss: 0.0783\n",
      "Validation Loss: 1.8460, Validation Accuracy: 0.6000\n",
      "Epoch 40/50, Loss: 0.0109\n",
      "Validation Loss: 1.5398, Validation Accuracy: 0.7500\n",
      "Epoch 41/50, Loss: 0.0257\n",
      "Validation Loss: 1.7595, Validation Accuracy: 0.7500\n",
      "Epoch 42/50, Loss: 0.0048\n",
      "Validation Loss: 1.9390, Validation Accuracy: 0.7500\n",
      "Epoch 43/50, Loss: 0.0030\n",
      "Validation Loss: 2.0811, Validation Accuracy: 0.7500\n",
      "Epoch 44/50, Loss: 0.0008\n",
      "Validation Loss: 2.1945, Validation Accuracy: 0.7500\n",
      "Epoch 45/50, Loss: 0.0008\n",
      "Validation Loss: 2.2587, Validation Accuracy: 0.7500\n",
      "Epoch 46/50, Loss: 0.0004\n",
      "Validation Loss: 2.3095, Validation Accuracy: 0.7500\n",
      "Epoch 47/50, Loss: 0.0247\n",
      "Validation Loss: 1.9817, Validation Accuracy: 0.8000\n",
      "Epoch 48/50, Loss: 0.1382\n",
      "Validation Loss: 2.1695, Validation Accuracy: 0.7500\n",
      "Epoch 49/50, Loss: 0.1982\n",
      "Validation Loss: 1.4899, Validation Accuracy: 0.7000\n",
      "Epoch 50/50, Loss: 0.0227\n",
      "Validation Loss: 1.0979, Validation Accuracy: 0.7500\n",
      "Model directory: C:\\School\\EE_Y3\\Q4\\BAP\\eeg_thesis_cnn_repo\\models\n",
      "Model filename: C:\\School\\EE_Y3\\Q4\\BAP\\eeg_thesis_cnn_repo\\models\\Advanced_EEG_MI_CNN_LSTM_Transformer_2024-06-08_16-01-15.pth\n",
      "Model saved as C:\\School\\EE_Y3\\Q4\\BAP\\eeg_thesis_cnn_repo\\models\\Advanced_EEG_MI_CNN_LSTM_Transformer_2024-06-08_16-01-15.pth\n"
     ]
    }
   ],
   "source": [
    "# Save the model with date and time in the filename\n",
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "# Example usage:\n",
    "model = Advanced_EEG_MI_CNN_LSTM_Transformer()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss = val_loss / len(val_loader.dataset)\n",
    "    val_accuracy = correct / total\n",
    "    print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "# Save the model with current date and time\n",
    "current_time = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "model_dir = r\"C:\\School\\EE_Y3\\Q4\\BAP\\eeg_thesis_cnn_repo\\models\"\n",
    "print(\"Model directory:\", model_dir)\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "model_filename = os.path.join(model_dir, f'{model.__class__.__name__}_{current_time}.pth')\n",
    "print(\"Model filename:\", model_filename)\n",
    "save_model(model, model_filename)\n",
    "print(f'Model saved as {model_filename}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
